<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>AI in Education: What Counts as Teaching?</title>
    <link rel="stylesheet" href="../styles.css" />
  </head>
  <body>
    <header class="container">
      <p><a href="index.html" class="blog-link">← All Thoughts</a></p>
      <h1 class="blog-title">AI in Education: What Counts as Teaching?</h1>
      <div class="blog-meta"><span class="blog-date">2025</span> · <span class="blog-category">Essay</span></div>
    </header>
    <main class="container" style="max-width: 80ch;">
      <h2 class="section-title" style="text-align:left;">Manuscript (LaTeX)</h2>
      <p class="section-description" style="text-align:left;">Draft LaTeX source included below for reference. If you prefer, I can render this to PDF and link it from here.</p>
      <pre style="white-space: pre-wrap; word-break: break-word; border:1px solid var(--border); border-radius:8px; padding:1rem; background:#fff; overflow:auto; max-height:70vh;"><code>\documentclass[11pt]{article}

% ----------------------------
% PACKAGES
% ----------------------------
\usepackage[margin=1in]{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{setspace}
\usepackage{amsmath, amssymb}
\usepackage[round,authoryear]{natbib}

% Allow good URL breaking (including at hyphens)
\usepackage[hyphens]{url}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{csquotes}

% Load hyperref *after* most packages
\usepackage[hidelinks]{hyperref}

% Make URL line-breaking a bit more flexible
\Urlmuskip=0mu plus 1mu\relax

% ----------------------------
% FORMATTING
% ----------------------------
\hypersetup{hidelinks}

\titleformat{\section}{\large\bfseries}{\thesection.}{0.75em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{0.75em}{}
\titleformat{\subsubsection}{\normalsize\itshape}{\thesubsubsection}{0.75em}{}

\pagestyle{fancy}
\fancyhf{}
\lhead{Evaluating AI in Education}
\rhead{\thepage}

% ----------------------------
% TITLE
% ----------------------------
\title{
\textbf{The Affordance Constraint: Agency, Accountability, and the Ontological Limits of LLMs in Education}
}

\author{
Kavita Kar \\
Philosophy of Education \\
}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This paper argues that large language models cannot replace human teachers because they lack the epistemic standing and moral accountability required for genuine pedagogy. Using a framework of pedagogical affordances, the analysis demonstrates that teaching depends on three fundamental capacities: theory of mind and student modeling, hierarchical agency and long-term planning, and moral accountability in testimony. Although AI systems can simulate the surface forms of explanation and feedback, they cannot instantiate the relational, normative, and epistemic conditions that make teaching possible. The proper role of AI in education is therefore instrumental rather than authoritative.
\end{abstract}

\vspace{1em}

% =========================================================
\section{Introduction}
% =========================================================

The integration of artificial intelligence into education raises a question that is epistemic before it is operational: What is the status of AI as a source of knowledge? Can a large language model (LLM) function as a teacher, or does treating it as one commit a category error that conflates performance with competence?

This inquiry is not speculative. Numerous institutions are actively experimenting with AI-led instructional models, deploying systems marketed not merely as repositories of information but as pedagogical agents capable of personalization, diagnosis, and guidance. The empirical literature on Intelligent Tutoring Systems (ITS) further supports optimism about such models. VanLehn's influential meta-analysis shows that well-designed ITS can approximate human tutoring effectiveness in procedural, well-structured domains such as elementary mathematics \citep{vanlehn2011relative}. Human tutors outperformed no tutoring with an effect size of approximately $d \approx 0.79$, while sophisticated, step-based ITS achieved roughly $d \approx 0.76$; in many domains, the difference between human tutors and ITS was statistically negligible. Recent adaptive platforms demonstrate measurable improvements in algorithmic subjects in which success can be quantified as procedural fluency, understood as the reliable execution of well-defined steps.

Intellectual integrity requires direct engagement with these findings. Systems that excel in diagnosing granular procedural errors and providing immediate corrective feedback constitute a significant advance in educational technology. For example, AI-driven systems can accelerate elementary mathematics learning by isolating specific gaps, such as identifying that a student's difficulty with long division stems from a subtraction error rather than a misunderstanding of the division algorithm. In medical education, randomized clinical trials report that AI tutoring systems can provide feedback on surgical simulations that leads to higher performance scores than remote expert instruction, primarily through continuous, metric-based assessment against quantifiable criteria.

This efficacy, however, is constrained by a crucial distinction between procedural gains and epistemic teaching. VanLehn's success cases, and those associated with modern adaptive platforms, are located primarily in domains where knowledge is algorithmic and answers are binary. The systems effectively fit curves to student performance in order to optimize procedural fluency. They function as sophisticated drill systems for cognitive logistics. Yet education is not merely the acquisition of procedures; it is the cultivation of conceptual understanding, the development of critical judgment, and the formation of epistemic agency.

I argue that these limitations are not temporary technical shortcomings or artifacts of current error rates. They arise from architectural and philosophical constraints that follow from the nature of LLMs and from the fundamental requirements of teaching.

\subsection*{Scope and Approach}

This paper deliberately evaluates the strongest claim: that LLMs could serve as complete replacements for human teachers, occupying equivalent epistemic roles and assuming comparable responsibilities. This replacement model is analytically distinct from:
\begin{itemize}[leftmargin=2em]
  \item course-helper models, in which AI functions as an auxiliary tool (calculator, reference, practice generator);
  \item hybrid infrastructure models, in which AI supports curriculum design and accessibility while humans retain epistemic authority.
\end{itemize}

I adopt the replacement model not because it reflects current educational consensus, but because it provides a clear test case. If LLMs cannot replace teachers even in principle, then debates about optimal human--AI partnerships gain clarity regarding where authority must remain.

The argument employs the concept of affordances, understood as structured possibilities for action that environments offer agents, to analyze teaching requirements and LLM capabilities. In educational contexts, pedagogical affordances are relational structures that connect students to legitimate epistemic sources: perception, reasoning, testimony, and memory. Human teachers occupy unique positions within these networks as epistemic agents capable of perception, accountable testimony, and rational justification.

I argue that LLMs interrupt this epistemic "throughline." They can simulate surface manifestations of perception (as if observed), reasoning (as if inferred), and testimony (as if asserted), but they do not engage in the underlying practices that confer epistemic significance on these forms. As \citet{bender2021stochastic} characterize them, LLMs are "stochastic parrots": systems that stitch together linguistic forms on the basis of probabilistic information about how such forms combine, without reference to meaning. This is not only an engineering issue but an ontological one.

The paper proceeds in five stages, culminating in constructive principles for responsible integration of AI into education.

% ... content continues ...

\end{document}
</code></pre>
    </main>
  </body>
  </html>
